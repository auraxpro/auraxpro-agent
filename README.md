# AuraXPro AI Agent - Secure Client-Side Architecture

A ChatGPT-like AI agent built with Next.js 15, TypeScript, and OpenAI SDK. **API key is secured server-side** while maintaining a fast, responsive client experience.

## ğŸ” Security Features

âœ… **API Key Protection** - Key stored server-side only, never exposed to client  
âœ… **API Route Proxy** - Secure Next.js API route handles OpenAI requests  
âœ… **Environment Variables** - Uses `OPENAI_API_KEY` (not `NEXT_PUBLIC_*`)  
âœ… **Error Handling** - Graceful error messages without exposing internals  

## ğŸš€ Quick Start

1. **Install dependencies:**
   ```bash
   npm install
   ```

2. **Set up your OpenAI API key:**
   Create `.env.local` file:
   ```env
   OPENAI_API_KEY=sk-your-key-here
   ```
   âš ï¸ **Important**: Use `OPENAI_API_KEY` (NOT `NEXT_PUBLIC_OPENAI_API_KEY`)

3. **Run the development server:**
   ```bash
   npm run dev
   ```

4. **Open your browser:**
   Navigate to `http://localhost:3000`

## ğŸ“¦ Tech Stack

- **Next.js 15** (App Router with API Routes)
- **TypeScript**
- **Tailwind CSS** (with dark mode support)
- **Zustand** (state management with localStorage persistence)
- **OpenAI JavaScript SDK** (server-side only)

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â””â”€â”€ route.ts      # Secure API route (server-side)
â”‚   â”œâ”€â”€ page.tsx              # Main page (renders Chat component)
â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â””â”€â”€ globals.css           # Global styles
â”œâ”€â”€ components/
â”‚   â””â”€â”€ Chat.tsx              # Main chat interface component
â”œâ”€â”€ store/
â”‚   â””â”€â”€ chatStore.ts          # Zustand store with localStorage persistence
â””â”€â”€ lib/
    â””â”€â”€ openaiServer.ts       # Server-side OpenAI client (secure)
```

## ğŸ”’ How Security Works

1. **Client** sends request to `/api/chat` (Next.js API route)
2. **API Route** (server-side) uses `OPENAI_API_KEY` from environment
3. **OpenAI SDK** processes request server-side
4. **Response** sent back to client (no API key exposed)

The API key **never** leaves the server. It's not in:
- âŒ Client-side JavaScript
- âŒ Browser network tab (only your API route URL)
- âŒ Bundled code
- âŒ Environment variables prefixed with `NEXT_PUBLIC_`

## âœ¨ Features

- âœ… **Secure API Key** - Protected server-side
- âœ… **Persistent History** - Chat history saved to localStorage
- âœ… **Dark Mode** - Toggle between light/dark themes
- âœ… **Responsive Design** - Works on all screen sizes
- âœ… **Loading States** - Smooth animations during API calls
- âœ… **Error Handling** - Graceful error messages
- âœ… **Auto-scroll** - Messages automatically scroll into view
- âœ… **Enter to Send** - Shift+Enter for new lines

## ğŸš¢ Deployment

### Vercel (Recommended)

1. Push your code to GitHub
2. Import project in Vercel
3. Add `OPENAI_API_KEY` to Vercel environment variables
4. Deploy!

**Important**: 
- âœ… Use `OPENAI_API_KEY` (not `NEXT_PUBLIC_OPENAI_API_KEY`)
- âœ… Never commit `.env.local` to git
- âœ… Set environment variable in Vercel dashboard

### Other Platforms

For other hosting platforms (Netlify, Railway, etc.):
- Set `OPENAI_API_KEY` as an environment variable
- Ensure Next.js API routes are supported
- The key will be available server-side only

## ğŸ¨ Customization

### Change System Prompt
Edit `src/lib/openaiServer.ts`:
```typescript
const SYSTEM_PROMPT = 'Your custom prompt here';
```

### Change Model
Edit `src/lib/openaiServer.ts`:
```typescript
model: 'gpt-4o-mini', // Change to 'gpt-4o', 'gpt-3.5-turbo', etc.
```

### Add Rate Limiting
You can add rate limiting to `src/app/api/chat/route.ts`:
```typescript
// Example: Simple rate limiting
const rateLimit = new Map();
// Add rate limiting logic here
```

## ğŸ“ License

MIT License - see LICENSE file
